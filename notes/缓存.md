# 缓存类型

## 本地缓存

本地缓存就是在进程的内存中进行缓存，比如JVM堆中，可以用LRUMap来实现，也可以使用Ehcache这样的工具来实现。

本地缓存是内存访问，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展。



## 分布式缓存

分布式缓存可以很好得解决本地缓存扩展性差的问题。

分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存。





## 多级缓存

为了平衡缓存情况，实际业务中一般采用多级缓存，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。

在目前的一线大厂中，这也是最常用的缓存方案，单考单一的缓存方案往往难以撑住很多高并发的场景。





# 缓存特征

## 命中率

当某个请求能够通过访问缓存而得到响应时，称为缓存命中。

缓存命中率越高，缓存的利用率也就越高。



## 最大空间

缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。

当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。



# 缓存更新

## Cache Aside

旁路缓存（Cache Aside Pattern）是最经典的缓存更新策略。

- 失效：应用程序先从缓存中取数据，没有取到，再从数据库中取数据，成功后，放到缓存中。
- 命中：应用程序从缓存中取数据，取到后返回。
- 更新：先把数据存到数据库中，成功后，再删除缓存。



该模式下可能存在的问题：

1. 某一时刻缓存刚好失效，请求A是查询操作，请求B是更新操作
2. 请求A查询数据库，得一个旧值
3. 请求B将新值写入数据库
4. 请求B删除缓存
5. 请求A将查到的旧值写入缓存

解决方案：

1. 不采取特别的措施。该问题需要读操作早于写操作发生，且晚于写操作结束，但读操作远远快于写操作，因此上述情况很少会发生。
2. 通过 2PC 或是 Paxos 协议保证一致性。



## Read/Write Through

Read/Write Through Pattern 的特点是把更新数据库的操作由缓存自己代理

### Read Through

Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside 是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载，从而对应用方是透明的。

### Write Through

Write Through 在更新数据时更新缓存。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

<img src="http://store.secretcamp.cn/uPic/image-202103231008421802021032310084216164653225xVElI5xVElI202103231008481616465328YgSJ1gYgSJ1g.png" alt="image-20210323100842180" style="zoom: 50%;" />



## Write Behind Caching

Write Behind 又叫 Write Back。Write back 就是 Linux 文件系统的 Page Cache 的算法。

Write back 在更新数据的时候，只更新缓存，不更新数据库，而缓存会异步地批量更新数据库。

优点：

- 因为是内存操作，数据的 I/O 操作飞快无比
- 异步更新数据库，可以合并对同一个数据的多次操作

缺点：

- 数据不是强一致性的，而且由于最新的数据存放在内存，所以可能会丢失



## FAQ

### 删除缓存还是更新缓存？

- 更新缓存：数据不但写入数据库，还会写入缓存

- 删除缓存：数据只会写入数据库，不会写入缓存



大多数情况下应该选择删除缓存，为什么是删除缓存，而不是更新缓存？

- 删除缓存实现更简单，副作用也仅仅只是增加了一次缓存未命中，因此是更加通用的处理方式。

- 更新缓存的代价有时很高。例如数据库更新了某个表的字段，但缓存中的值必须不仅仅是取出这个值，而是要进行联表查询，才能得出缓存最新的值。
- 更新的缓存不一定会被频繁访问。如果更新了缓存但是很少被读取，那么缓存数据就是冷数据，更新则是不必要的，所以缓存应该在它被需要的时候才被更新。

但更应该根据具体情况选择，这两者的选择主要取决于 “更新缓存的复杂度” 。

如果更新缓存的代价很小，那么应该更倾向于更新缓存，以保证更高的缓存命中率。



---

案例：

如果用户余额为 money，商品的价格是 price，这个商品从属于 type 类，type 类在做促销活动要打折扣，这个商品价格的计算就比较复杂。

1）先把商品的品类，价格取出来：`SELECT type, price FROM product WHERE pid=XXX`

2）再把这个品类的折扣取出来：`SELECT rate FROM discount WHERE type=XXX`

3）再把原有价格从缓存中查询出来 `money = getCache(uid)`

4）再把新的余额写入到缓存中去 `setCache(uid, money-price*rate)`

更新缓存的代价很大，此时我们应该更倾向于删除缓存。



### 删除缓存失败怎么办



# 缓存淘汰

当缓存使用的内存空间被用尽的时候，就需要淘汰掉一些不需要的数据，以什么样的方法判断淘汰哪些数据就是「缓存淘汰机制」



## FIFO

FIFO（First In First Out）指先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。



## LRU

LRU（Least Recently Used）指最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。



## LFU

LFU（Least Frequently Used）指最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。





# 缓存位置

## 浏览器

当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。

## ISP

网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。

## 反向代理

反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。

## 本地缓存

使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。

## 分布式缓存

使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。

相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。

## 数据库缓存

MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。

## Java 内部的缓存

Java 为了优化空间，提高字符串、基本数据类型包装类的创建效率，设计了字符串常量池及 Byte、Short、Character、Integer、Long、Boolean 这六种包装类缓冲池。

## CPU 多级缓存

CPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。



# CDN

内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。

CDN 主要有以下优点：

- 更快地将数据分发给用户；
- 通过部署多台服务器，从而提高系统整体的带宽性能；
- 多台服务器可以看成是一种冗余机制，从而具有高可用性。





# 缓存问题

## 缓存雪崩

缓存雪崩是指由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。

<img src="http://store.secretcamp.cn/uPic/image-20210319150859009202103191508591616137739Zk2ZvYZk2ZvY.png" alt="image-20210319150859009" style="zoom:38%;" />

场景：

电商首页以及热点数据都会去做缓存，一般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有一个问题。如果所有首页的Key失效时间都是12小时，第一天中午12点刷新缓存，第二天零点有个秒杀活动会有大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 6000 个请求全部落在数据库，数据库必然扛不住，它会报一下警，真实情况可能 DBA 都没反应过来就直接挂了。此时，如果没用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。



解决方案：

- 缓存过期时间可以加上一个随机数，避免大量缓存同时失效
- 可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。
- 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。





## 缓存穿透

缓存穿透指的是对缓存和数据库中都不存在的数据进行请求，该请求将会穿透缓存到达数据库。



场景：

数据库的 id 都是从 1 开始自增上去的，如发起为 id=-1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。



解决方案：

- 对这些不存在的数据缓存一个空数据；
- 对这类请求进行过滤，在接口层对用户、参数等作校验，不合法的请求直接 return





## 缓存击穿

缓存击穿与缓存雪崩有些类似，缓存雪崩是大面积的缓存失效打崩了数据库，缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

解决方案：

- 设置热点数据永不过期



## 缓存一致性

缓存一致性要求数据更新的同时缓存数据也能够实时更新。

解决方案：

- 在数据更新的同时立即去更新缓存；
- 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。

要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。



## 缓存 “无底洞” 现象

指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。

产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。

解决方案：

- 优化批量数据操作命令；
- 减少网络通信次数；
- 降低接入成本，使用长连接、连接池、NIO 等。