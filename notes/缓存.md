# 缓存类型🧬

## 本地缓存

本地缓存就是在进程的内存中进行缓存，比如 JVM 堆中，可以用 LRUMap 来实现，也可以使用 Ehcache 这样的工具来实现。

本地缓存是内存访问，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展。



## 分布式缓存

分布式缓存可以很好得解决本地缓存扩展性差的问题。

分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存。



## 多级缓存

为了平衡缓存情况，实际业务中一般采用多级缓存，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。

在目前的一线大厂中，这也是最常用的缓存方案，单考单一的缓存方案往往难以撑住很多高并发的场景。





# 缓存特征🧬

## 命中率

当某个请求能够通过访问缓存而得到响应时，称为缓存命中。

缓存命中率越高，缓存的利用率也就越高。



## 最大空间

缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。

当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。



# 双写一致性方案🧬

## 旁路缓存 Cache Aside

旁路缓存（Cache Aside Pattern）是最经典的缓存更新策略。

- 命中：应用程序从缓存中取数据，取到后返回。
- 失效：应用程序先从缓存中取数据，没有取到，再从数据库中取数据，成功后，放到缓存中，最后返回。
- 更新：先更新数据库，成功后再删除缓存；或者先删除缓存，成功后再更新数据库



### 更新数据库or更新缓存

- 更新缓存：数据不但写入数据库，还会写入缓存

- 删除缓存：数据只会写入数据库，不会写入缓存



大多数情况下应该选择删除缓存，为什么是删除缓存，而不是更新缓存？

- 可能导致缓存不一致，例如请求 A、B 更新数据库，请求 A 先更新数据库，请求 B 后更新数据库，但是因为网络原因，B 的值先被写入缓存然后被 A 覆盖，这样就出现了脏数据。

- 删除缓存实现更简单，副作用也仅仅只是增加了一次缓存未命中，因此是更加通用的处理方式。
- 更新缓存的代价有时很高。例如数据库更新了某个表的字段，但缓存中的值必须不仅仅是取出这个值，而是要进行联表查询，才能得出缓存最新的值。
- 更新的缓存不一定会被频繁访问。如果更新了缓存但是很少被读取，那么缓存数据就是冷数据，更新则是不必要的，所以缓存应该在它被需要的时候才被更新。

但更应该根据具体情况选择，这两者的选择主要取决于 “更新缓存的复杂度” 。

如果更新缓存的代价很小，那么应该更倾向于更新缓存，以保证更高的缓存命中率。但一般更新缓存的代价很大，此时我们应该更倾向于删除缓存。



### 先更新数据库再删缓存



<img src="http://store.secretcamp.cn/uPic/image-20210914231908882202109142319091631632749zY6CiKzY6CiK.png" alt="image-20210914231908882" style="zoom:50%;" />



### 先删除缓存再更新数据库

由于读操作远快于写操作，这种方案很容易产生数据的不一致

<img src="http://store.secretcamp.cn/uPic/image-20210914232431262202109142324311631633071frNvhdfrNvhd.png" alt="image-20210914232431262" style="zoom:50%;" />



### 缓存延时双删

综合以上两点，无论是 “先更新数据库再删缓存” 还是 “先删除缓存再更新数据库” 都会破坏数据的一致性，所以这里提出 “缓存延时双删” 策略来保证数据一致性，该方案基于 “先删除缓存再更新数据库”。

1. 先删除缓存
2. 再更新数据库
3. 休眠一会（比如 1 秒），再次删除缓存。

<img src="http://store.secretcamp.cn/uPic/image-20210914232642927202109142326431631633203P16IcYP16IcY.png" alt="image-20210914232642927" style="zoom:50%;" />



如果延时删缓存失败怎么办？引入重试机制





## 读写穿透 Read/Write Through

读写穿透模式（Read/Write Through Pattern） 的特点是服务端把缓存作为主要数据存储，缓存不会过期，屏蔽了底层数据库的操作，只操作缓存，把更新数据库的操作由抽象缓存层 Cache Provider 实现。

用于读操作较多、相较于 Cache aside 而言更要求缓存一致性的场景。

1. Read Through

   Read Through 在查询操作中更新缓存，与旁路缓存流程上一样，但旁路缓存是应用程序来执行操作，而 Read Through 通过抽象缓存层 Cache Provider 来进行，

   <img src="http://store.secretcamp.cn/uPic/image-20210816200028346202108162000281629115228DN2gwcDN2gwc.png" alt="image-20210816200028346" style="zoom:50%;" />





2. Write Through

   Write Through 在更新数据时，通过 Cache Provider 更新缓存。

   先查询要更新的数据在缓存中是否存在，命中了更新缓存中的数据，然后再由 Cache Provider 更新数据库（这是一个同步操作）

   如果没有命中，就出现问题了，这种情况叫做 Write Miss（写失效），可以鸵鸟策略直接将数据写入缓存。

   <img src="http://store.secretcamp.cn/uPic/image-20210816200049550202108162000491629115249dwKSZCdwKSZC.png" alt="image-20210816200049550" style="zoom:60%;" />





## 异步缓存写入 Write Behind

异步缓存写入（Write Behind） 是相较于 Write Through 而言的一种异步回写策略.

Write back 在更新数据的时候，只更新缓存，不更新数据库，而缓存会异步地批量更新数据库。

<img src="http://store.secretcamp.cn/uPic/image-20210816201915688202108162019151629116355C2LG0QC2LG0Q.png" alt="image-20210816201915688" style="zoom:60%;" />

优点：

- 适合读少写多的场景，因为是内存操作，数据的 I/O 操作飞快无比
- 异步更新数据库，可以合并对同一个数据的多次操作，减少与物理磁盘存储的交互

缺点：

- 数据不是强一致性的，而且由于最新的数据存放在内存，容易丢数据

















# 缓存淘汰算法🧬

当缓存使用的内存空间被用尽的时候，就需要淘汰掉一些不需要的数据，以什么样的方法判断淘汰哪些数据就是「缓存淘汰机制」



## FIFO

FIFO（First In First Out）指先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。



## LRU

LRU（Least Recently Used）指最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。



## LFU

LFU（Least Frequently Used）指最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。





# 缓存位置🧬

## 浏览器

当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。



## ISP

网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。



## 反向代理

反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。



## 本地缓存

使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。



## 分布式缓存

使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。

相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。



## 数据库缓存

MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。



## Java内部的缓存

Java 为了优化空间，提高字符串、基本数据类型包装类的创建效率，设计了字符串常量池及 Byte、Short、Character、Integer、Long、Boolean 这六种包装类缓冲池。



## CPU多级缓存

CPU 为了解决运算速度与主存 I/O 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。



# CDN🧬

内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。

CDN 主要有以下优点：

- 更快地将数据分发给用户；
- 通过部署多台服务器，从而提高系统整体的带宽性能；
- 多台服务器可以看成是一种冗余机制，从而具有高可用性。



CDN的实现分为三类：镜像、高速缓存、专线。

## 镜像站点

镜像站点（Mirror Site）是最常见的，它让内容直接发布，适用于静态和准动态的数据同步。但是购买和维护新服务器的费用较高，还必须在各个地区设置镜像服务器，配备专业技术人员进行管理与维护。对于大型网站来说，更新所用的带宽成本也大大提高了。



## 高速缓存

高速缓存，成本较低，适用于静态内容，CDN 服务一般会在全国范围内的关键节点上放置缓存服务器。



## 专线

让用户直接访问数据源，可以实现数据的动态同步。



# 缓存问题🧬

## 缓存雪崩

缓存雪崩是指由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。

<img src="http://store.secretcamp.cn/uPic/image-20210319150859009202103191508591616137739Zk2ZvYZk2ZvY.png" alt="image-20210319150859009" style="zoom:38%;" />

场景：

电商首页以及热点数据都会去做缓存，一般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有一个问题。如果所有首页的 Key 失效时间都是 12 小时，第一天中午 12 点刷新缓存，第二天零点有个秒杀活动会有大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的 Key 都失效了。此时 1 秒 6000 个请求全部落在数据库，数据库必然扛不住，它会报一下警，真实情况可能 DBA 都没反应过来就直接挂了。此时，如果没用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。



解决方案：

- 缓存过期时间可以加上一个随机数，避免大量缓存同时失效
- 可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。
- 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。





## 缓存穿透

缓存穿透指的是对缓存和数据库中都不存在的数据进行请求，该请求将会穿透缓存到达数据库。



场景：

数据库的 id 都是从 1 开始自增上去的，如发起为 id=-1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。

解决方案：

- 对这些不存在的数据缓存一个空数据，如果缓存和数据库都查不到某个 key 的数据就写到 Redis 中去并设置过期时间，这种方式可以解决请求的 key 变化不频繁的情况。

  但如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。

- 对这类请求进行过滤，在接口层对用户、参数等作校验，不合法的请求直接 return，对相同 ip 做限流。

- 使用布隆过滤器，把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中，不存在的话，直接返回请求参数错误信息给客户端。





## 缓存击穿

缓存击穿与缓存雪崩有些类似，缓存雪崩是大面积的缓存失效打崩了数据库，缓存击穿是指一个 Key 非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个 Key 在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

解决方案：

- 设置热点数据永不过期



## 缓存一致性

缓存一致性要求数据更新的同时缓存数据也能够实时更新。

解决方案：

- 在数据更新的同时立即去更新缓存；
- 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。

要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。



## 缓存 “无底洞” 现象

指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。

产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。

解决方案：

- 优化批量数据操作命令；
- 减少网络通信次数；
- 降低接入成本，使用长连接、连接池、NIO 等。









