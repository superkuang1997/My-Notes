#  操作系统概述🔥

## 基本概念

### 并发与并行

- 并发：指两个或多个时间在同一时间间隔内发生。操作系统的并发性指计算机系统中同时存在多个运行的程序，宏观上有多道程序同时执行，微观上在每个时刻，单处理器环境下仅有一道程序可以被执行，多道程序的执行是分时交替的。
- 并行：是计算机系统中能同时执行两个或更多个处理的一种计算方法。并行处理可同时工作于同一程序的不同方面，主要目的是节省大型和复杂问题的解决时间。

> 并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。



### 共享

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。

- 互斥共享

  互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

  进程 A 访问某个资源时，必须先提出请求，若此时该资源空闲，系统则将其分配给进程 A 使用。

- 同时访问

  系统中还有一类资源，例如磁盘等，可以允许在一段时间内由多个进程 “同时” 访问，这个 “同时” 是宏观意义上的，微观上进程可能是交替地对资源进行访问，即 “分时共享”。

  互斥共享要求一种资源在一段时间（哪怕是很短的时间）都只能满足一个请求，否则会出现严重的问题，而同时共享通常要求一个请求分几个时间片间隔地去完成。



### 虚拟

虚拟技术把一个物理实体转换为多个逻辑实体，操作系统中利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备等。

主要有两种虚拟技术：

- 时分复用

  多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。这样虽然只有一个 CPU，但它能同时为多个用户服务，使每个终端用户都感觉有一个CPU在专门为自己服务。

- 空分复用

  虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时（在外存中），执行页面置换算法，将该页置换到内存中。



### 同步和异步

- 同步：指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么这个进程将会一直等待下去，直到收到返回信息才继续执行下去。

- 异步：指进程不需要一直等待下去，而是继续执行下面的操作，不管其他进程的状态，当有消息返回时系统会通知进程进行处理，这样可以提高执行效率



## 操作系统的发展

1. 手工操作阶段
2. 批处理阶段
3. 分时操作系统
4. 实时操作系统
5. 分布式系统
6. 个人计算机操作系统



## 运行机制

### 时钟管理

系统管理的各方面均依赖于时钟。

时钟的第一功能是计时，操作系统通过时钟管理向用户提供标准的系统时间；通过时钟中断实现进程的切换；在分时操作系统中的时间片轮转也依赖于时钟。



### 中断

中断技术是为了提高多道程序环境中 CPU 的利用率。

中断机制中，只有一小部分功能属于内核，它们负责保护和回复中断现场的信息，转移控制权到相关的处理程序。



### 原语

计算机进程的控制通常由原语完成。

所谓原语，一般是指由若干条指令组成的程序段，用来实现某个特定功能，在执行过程中不可被中断。

- 处于操作系统的最底层，最接近于硬件
- 运行具有原子性
- 调用时间较短，而且调用频繁

因为原语具有原子性，所以定义原语的直接方法是关闭中断，其动作执行完后再打开中断。





## 中断和异常

操作系统分为内核态和用户态，操作系统内核工作在核心态，用户程序工作在内核态，系统不允许用户态实现核心态的功能，但是又必须使用这些功能，那么就必须通过中断或异常来实现。



### 异常的概念

异常也称为内中断，是指由 CPU 内部异常引起的意外事件，分为硬故障中断和程序性异常。

- 硬故障中断：由硬连线出现异常引起的，如电源掉电、存储器线路错等。
- 程序性异常：也称软中断，是指在 CPU 内部因执行指令而引起的异常事件。如整除 0、溢出、断点、单步跟踪、非法指令、栈溢出、地址越界、缺页、分时系统中的时间片中断及用户态到核心态的切换等。



### 中断的概念

中断也称为外中断，指来自 CPU 外部、与 CPU 执行指令无关的事件引起的中断。

- I/O中断（键盘输入、打印机缺纸）
- 外部信号中断（用户按 Esc 键）
- 时钟中断（定时器中一个固定的时间片已到）
- 外设中断：串口、硬盘、网卡、时钟



### 中断请求

中断源是请求 CPU 中断的设备或事件，一台计算机允许有多个中断源，每个中断源向 CPU 发出中断请求的时间是随机的，为记录中断事件并区分不同的中断源，中断系统需对每个中断源设置中断请求标记触发器 INTR，当其状态为 1 时，表示中断源有请求。

内中断皆为不可屏蔽中断。通过 INTR 信号线发出的外中断是可屏蔽中断，在关中断的情况下不会被响应，而通过 NMI 信号发出的是不可屏蔽中断，即使在关中断 的情况下也会被响应。



### 中断判优

- 硬件故障中断 > 软件中断

- 不可屏蔽中断 > 可屏蔽中断

- DMA 请求 > I/O 设备的中断请求

- 高速设备 > 低速设备

- 输入设备 > 输出设备



### CPU响应中断的条件

1. 中断源有中断请求。
2. CPU 允许中断及开中断。

3. 一条指令执行完毕，且没有更紧迫的任务。



### 中断处理的过程

CPU 对于中断和异常的具体处理机制本质上是完全一致的，每个中断或异常与一个中断服务例程（ISR，Interrupt Server Routine) 关联，其关联关系存储在中断描述符表（IDT，interrupt Descriptor Table）。

1. 关中断：CPU 响应中断后，首先要保护程序的现场状态，这个时候 CPU 是不允许被其他的程序打扰的，也不会响应更高级中断源的中断请求，否则现场保存不完整，到时候恢复现场也不正确。

   > CPU 的关中断是指即使 CPU 的中断线上来了中断信号，也不要响应中断

2. 保存断点：将原来程序的断点（即程序计数器）保存起来。

3. 引出中断服务程序：取出中断服务程序的入口地址送入程序计数器。

4. 保存现场和屏蔽字：进入中断服务程序之后，首先要保存现场。现场一般指程序状态字寄存器和某些通用寄存器的内容。

5. 开中断：允许更高级中断请求得到响应

6. 执行中断服务程序：这是中断请求的目的

7. 关中断：保证在恢复现场和屏蔽字时不被中断

8. 恢复现场和屏蔽字：将现场和屏蔽字恢复到原来的状态

9. 开中断、中断返回：执行中断服务程序的最后一条指令，即回到原程序的断点处，以便继续执行原程序。

<img src="http://store.secretcamp.cn/uPic/image-20210805200227011202108052002271628164947iXJvNziXJvNz.png" alt="image-20210805200227011" style="zoom:50%;" />



## 系统调用

### 用户空间和内核空间

操作系统为了保证系统的稳定性、支持多个进程同时运行且保证不同进程之间相对独立，即一个进程的崩溃不会影响其他的进程，恶意进程不能直接读取和修改其他进程运行时的代码和数据。因此操作系统内核需要拥有高于普通进程的权限，以此来调度和管理用户的应用程序。

于是内存空间被划分为两部分，一部分为内核空间，一部分为用户空间，内核空间存储的代码和数据具有更高级别的权限。内存访问的相关硬件在程序执行期间会进行访问控制（Access Control），使得用户空间的程序不能直接读写内核空间的内存。

系统调用将操作系统的整个体系分为「用户态」和「内核态」。

每个进程都有两个堆栈，分别用于用户态和内核态程序的执行，我们称为用户态堆栈和内核态堆栈。

- 内核态：内核是一种特殊的软件程序，它控制计算机的硬件资源，例如协调 CPU 资源，分配内存资源，并且提供稳定的环境供应用程序运行。

- 用户态：提供应用程序运行的空间，为了使应用程序访问到内核管理的资源例如 CPU、内存、I/O ，内核必须提供一组通用的访问接口，这些接口就叫系统调用。



### 系统调用的方式

从用户态到内核态切换可以通过三种方式：

① 系统调用，这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。

② 异常：当 CPU 在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

③ 外设中断：当外设完成用户的请求时，会向 CPU 发送中断信号。这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。





# 进程管理🔥

## 进程与线程

### 进程

进程是系统资源分配的基本单位。系统资源是指处理器、存储器和其他设备服务于某个进程的 “时间”。

程序之间需要共享系统资源，因此会导致各程序在执行过程中出现相互制约的关系，程序的执行会表现出间断性的特征，为了深刻描述程序执行时动态性的特征，于是引入了进程的概念。引入进程的目的是为了更好的让多个程序并发执行，提高资源利用率和系统吞吐量。

下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。

![](http://store.secretcamp.cn/uPic/PT012021020220260616122687662N9M3A2N9M3A.png)



### 线程

线程由线程 ID 、程序计数器、寄存器和堆栈组成，是 CPU 调度的基本单位，一个进程中可以有多个线程，它们共享进程资源。

引入线程的目的是为了减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。

在单核计算机中，各线程可交替地占用 CPU ，在多核计算机中，各线程可同时占用不同的 CPU ，如果各个不同的 CPU 同时为一个进程中的不同线程服务，则可以缩短处理时间。



### 进程与线程的区别

- 拥有资源

  进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

  若线程也拥有资源，那么切换线程就需要较大的时空开销，那么线程这个概念的提出就没有意义了。

- 调度

  线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

- 系统开销

  由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

- 通信方面

  线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。



### 协程

操作系统在线程等待 IO 的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待 IO 的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题。

一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间。

协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。

线程在等待 IO 的过程中会陷入阻塞状态，协程只有在等待 I/O 的过程中才能重复利用线程，所以需要注意的是，协程中不能调用导致线程阻塞的操作，因为如果协程调用阻塞 I/O 操作，操作系统就会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的所有协程都会陷入阻塞，这是不能接受的，所以需要将协程与异步 I/O 结合使用。





## 进程的组织结构

进程由程序段、相关数据段与进程控制块（Process Control Block，PCB）组成。



### PCB

PCB 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作，PCB 是进程存在的唯一标识。

进程执行时，系统通过 PCB 了解进程的现行状态信息，以便对其进行控制和管理。

包括以下四类信息：

1. 进程描述信息
2. 进程控制和管理信息
3. 资源分配清单
4. 处理器相关信息



PCB 的组织形式有两种方式：

1. 链接方式：将同一状态的 PCB 链接成一个队列，不同状态对应了不同队列。
2. 索引方式：将同一状态的进程组织在一个索引表中，索引表的表项指向对应的 PCB。



### 程序段

程序段就是能被进程调度程序调度到CPU后执行的程序代码段。



### 数据段

数据段是指进程执行时产生的中间或最终结果数据。







## 进程状态的切换

<img src="http://store.secretcamp.cn/uPic/PT03202102022026511612268811s701iYs701iY.png" style="zoom: 67%;" />

- 运行态：进程正在处理器上运行。在单核 CPU 下，每个时刻只有一个进程处于运行态。
- 就绪态：进程获得了除 CPU 时间以外的一切资源，一旦被 CPU 分配时间，便可立即运行。
- 阻塞态：进程正在等待某一事件而暂停运行，如等待某资源为可用或者 I/O 完成，即时 CPU 空闲该进程也不能运行。
- 创建态：进程正在被创建，尚未转到就绪态。
- 结束态：进程正从系统中消失。可能是正常结束或中断退出，系统会将进程设置为结束态，然后进一步释放资源。

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括CPU时间，缺少CPU时间会从运行态转换为就绪态。



## 进程控制

### 进程创建

操作系统允许一个进程创建另一个进程，此时创建者称为父进程，被创建者称为子进程，子进程可以继承父进程所拥有的资源。

创建原语：

- 为新进程分配一个唯一标识，并申请一个空白的 PCB ，若 PCB 申请失败则创建失败。
- 为进程分配资源，若资源不足则进入阻塞态。
- 初始化 PCB ，主要包括初始化标志信息、处理器状态信息以及进程优先级等。
- 若进程就绪队列能够接纳新进程，则进入就绪状态。



### 进程终止

子进程被撤销时，应该归还从父进程处获得的资源。撤销父进程时，必须同时撤销所有子进程。

引起进程终止的事件主要有：

- 正常结束
- 异常结束
- 外界干预



### 进程的阻塞与唤醒

正在执行的线程，如果请求系统资源失败、等待某种操作的完成、新数据未到达或尚无工作可做时，由系统自动执行阻塞原语（Block），是自己由运行态转为阻塞态。

当被阻塞进程所期待的事件出现时，由相关进程调用唤醒原语（Wakeup）将等待该事件的线程唤醒。



### 进程切换

进程切换是指 CPU 从一个线程的运行转到另一个线程的运行。

进程切换的过程：

- 保存处理器上下文，包括程序计数器以及其他寄存器
- 更新 PCB 信息
- 把进程的 PCB 移入相应的队列，如就绪、阻塞队列
- 选择另一个进程执行，更新其 PCB
- 更新内存管理的数据结构
- 恢复处理器上下文





## 进程调度

### 调度的概念

系统中进程的数量往往大于 CPU 的个数，因此一定会有程序对 CPU 的争用，调度就是对 CPU 资源进行分配，从进程就绪队列中按照一定的算法选择一个进程分配给 CPU 运行。



### 调度算法

1. 先来先服务

   非抢占式的调度算法，按照请求的顺序进行调度。

   有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

2. 短作业优先

   非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

   长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

3. 最短剩余时间优先

   最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

4. 优先级调度

   为每个进程分配一个优先级，按优先级进行调度。

   为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

5. 时间片轮转

   将所有就绪进程按先来先服务的原则排成一个队列，每次调度时，把 CPU 时间分配给队首的进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

   时间片轮转算法的效率和时间片的大小有很大关系：

   - 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
   - 而如果时间片太大，则算法退化为先来先服务。

6. 多级反馈队列 👍

   一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

   多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同（例如1, 2, 4, 8...）。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换7次。

   每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度下一个队列上的进程。

   可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。





## 进程间通信

### 同主机进程间通信

进程间通信指进程之间的信息交换。PV 操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式，主要有以下三种方式。

#### 共享内存

共享内存允许两个或更多进程访问同一块内存，也就是在通信的进程之间存在一块可以直接访问的共享空间，通过对这片共享空间进行读写操作实现进程之间的信息交换。进程之间共享空间必须通过特殊的系统调度，进程中的线程是天然共享进程空间

操作系统只负责为通信的双方进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排。



因为所有进程共享同一块内存，共享内存在各种进程间通信方式中具有最高的效率。访问共享内存区域和访问进程独有的内存区域一样快，并不需要通过系统调用或者其它需要切入内核的过程来完成。

但是因为系统内核没有对访问共享内存进行同步，用户必须提供自己的同步措施。例如，在数据被写入之前不允许进程从共享内存中读取信息、不允许两个进程同时向同一个共享内存地址写入数据等。解决这些问题的常用方法是通过使用信号量进行同步。



#### 消息队列

消息队列是指进程间的数据交换是以格式化的消息（Message）为单位的。

若通信的双方进程之间不存在互斥的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信，进程通过操作系统提供的「发送消息」和「接收消息」两个原语进行数据交换。

- 直接通信：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列之中获取消息。
- 间接通信：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息，例如电子邮件。



缺点：

- 消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限的。

- 消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。



#### 管道通信

管道通信是消息队列的一种特殊形式，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名 pipe 文件。

两个进程利用管道文件进行通信时，一个进程为写进程，另一个进程为读进程。写进程往管道文件中写入信息，读进程从管道文件中读取信息，两个进程协调不断地进行写、读，便会构成双方通过管道传递信息的流水线。

- 匿名管道：管道是半双工的，数据只能单向通信，需要双方通信时，需要建立起两个管道，只能用于父子进程或者兄弟进程之间。
- 命名管道：可在同一台计算机的不同进程之间或在跨越一个网络的不同计算机的不同进程之间，支持可靠的、单向或双向的数据通信

从管道中读数据是一次性操作，数据一旦被读取就会被移出管道。管道只能采用半双工通信，即某一时刻只能单向传输，要实现父子进程双方互动通信，需要定义两个管道。



### 跨主机进程间通信

#### Socket

共享内存、消息队列、管道都是在同一台主机上进行进程间通信，想跨网络与不同主机上的进程之间通信，就需要 Socket 通信。







## 进程同步

### 进程同步的概念

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

在操作系统中，进程是并发执行的，不同进程之间存在相互制约的关系，进程同步就是为了调节这种制约关系。

例如希望 $1 + 2\times3$ 的结果是正确的，那必须令乘法作用在加法之前。



#### 临界区

在系统中的许多资源是互斥共享的，一次只能为一个进程所用，这些资源被称为 "临界资源"

对临界资源的访问必须互斥进行，进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。



#### 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。



### 信号量

信号量（Semaphore）是一个整形变量，只能被两个标准的原语 wait(S) 和 signal(S) 访问，也就是 P 和 V 操作。

sephemor = 0 表示资源可用，sephemor < 0 表示资源被占用。

- wait（P，请求资源） : 如果信号量大于0，执行 -1 操作；如果信号量等于0，进程睡眠，等待信号量大于0；
- signal（V，释放资源） ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 wait 操作。

wait 和 sighal 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。



#### 整形信号量

在以下实现中，只要信号量 `S <= 0` ，就会不断被测试，直到 `S > 0` 才执行 `S = S - 1` ，因此是处于一种 "忙等" 的状态。

```c
wait(S) {
		while (S <= 0);
		S = S - 1;
}
signal(S) {
		S = S + 1;
}
```



#### 记录性信号量

记录性信号量不存在 “忙等” ，而是实现了 “让权等待”

`wait` 操作中的 `S.value--` 表示进程请求资源，当 `S.value < 0` 时，表示该类资源已经分配完毕，于是进程调用 block 原语进行自我阻塞，进入等待队列之中。

`signal` 操作中的 `S.value++` 表示进程释放资源，在系统中可供配置的资源数量 +1，如果 +1 后 `S.value <= 0` 则等待队列中的进程继续等待，否则就将等待队列中的第一个进程唤醒。

```c
void wait(semaphore S) {
		S.value--;
    if (S.value < 0) {
				// 将进程P加入等待队列S.L
      	block(S.L)
    }
}
void signal(semaphore S) {
 	 S.value++;
   if (S.value <= 0) {
      // 将进程P从等待队列中移除
     	wakeup(P);
   }
}
```



#### 信号量实现同步

假设进程 S2 的语句 y 需要 S1 的运算结果 x

```c
semaphore S = 0;
S1() {
    ...
    x; 
    V(S);  // 调用V操作，表示P1中操作完成
    ...
}

S2() {
    ...
    P(S);  // 调用P操作，查看P1中是否操作完成
    y;
    ...
}
```



#### 信号量实现互斥

```c
semaphore S = 0;
S1() {
    ...
    P(S);
    ...
    V(S);  // 调用V操作，表示P1中操作完成
    ...
}

S2() {
    ...
    P(S);  // 调用P操作，查看P1中是否操作完成
    ...
    V(S);
    ...
}
```





### 管程

在信号量机制中，每个访问临界资源的操作都必须自带 PV 操作，使用较为繁琐而且操作不当就会容易造成死锁。

管程是一种新的进程同步工具，其特性保证了进程互斥，因此无需程序员自己实现互斥，降低了死锁发生的概率。



#### 管程的概念

管程非常像一个类，它时代表共享资源的数据结构以及对这个数据结构进行操作的过程所组成的资源管理程序。

- 共享数据结构：用于表示系统中的共享资源，忽略其内部的结构与实现细节

- 过程：指对数据结构进行一组操作。

  进程对共享资源的申请、释放等操作，都要通过过程实现，过程还可以根据资源的情况接收或阻塞进程的访问，确保每次只有一个进程能够使用共享资源。

```c
monitor Demo {
		init_code() {
        S = 5;  // 初始资源数等于5
		}
		take_away() {
        S--;  // 申请一个资源 
        ...
		}
		
		give_back() {
				S++;  // 归还一个资源
				...
		}
}
```

管程有两个特性：

- 管程内的共享数据结构只能被管程内的过程访问，因此一个进程只有通过调用管程内的过程才能访问共享资源

- 每次只允许一个进程进入管程，从而实现进程互斥，若多个进程同时调用管程内的过程，则只有在某个进程完成调用后，下个进程才能开始新的调用。



#### 条件变量

管程引入了条件变量以及相关的操作： `wait()` 和 `signal()` 来实现同步操作。对条件变量执行 `wait()` 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。 `signal()` 操作用于唤醒被阻塞的进程。



### 经典同步问题

#### 生产者消费者问题

#### 读者写者问题



# 死锁🔥

## 死锁的概念

死锁是指多个进程因竞争资源而造成互相等待，如无外力作用，所有进程都无法向前推进。



## 死锁的四个必要条件

- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。





## 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它







## 死锁预防

在程序运行之前预防发生死锁，破坏死锁发生的四个必要条件之一。

优点：实现较为简单

缺点：保守、宁可资源闲置，导致系统的效率低

- 破坏互斥条件

  例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

- 破坏请求并保持条件

  一种实现方式是规定所有进程在开始执行前请求所需要的全部资源，缺点也很明显，就是造成了系统资源的严重浪费

- 破坏不可抢占条件

  释放已经获得的资源可能造成前一阶段工作的失效，一般用于状态易于保存和恢复的资源，如 CPU 寄存器及内存资源。

- 破坏环路等待

  给资源统一编号，进程只能按编号顺序来请求资源。







## 死锁避免

死锁避免属于事前预防策略，但不是破坏死锁发生的必要条件，而是在资源动态分配的过程，防止系统进入不安全状态。

优点：相对死锁预防，限制条件较为宽松

缺点：需要借助复杂的算法，实现较为复杂

- 银行家算法
- 安全性算法





## 死锁的检测与解除

### 死锁检测

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

1. 每种类型一个资源的死锁检测

   ![](http://store.secretcamp.cn/uPic/deadlock12021020220572516122706451sdYIx1sdYIx.png)

   上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

   图 a 可以抽取出一个环路，如图 b 所示，它满足了环路等待条件，因此会发生死锁。

   每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。



2. 每种类型多个资源的死锁检测

   ![](http://store.secretcamp.cn/uPic/deadlock2202102022057331612270653lKpqdklKpqdk.png)

   上图中，有三个进程四个资源，每个数据代表的含义如下：

   - E 向量：资源总量

   - A 向量：资源剩余量

   - C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量

   - R 矩阵：每个进程请求的资源数量

   进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 `A = (2 2 2 0)`。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

   算法总结如下：

   每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，非死锁的进行都会被标记，任何没有被标记的进程都是死锁进程。

   1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
   2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
   3. 如果没有这样一个进程，算法终止。





### 死锁解除

- 资源剥夺法：挂起死锁进程并抢占它的资源
- 撤销进程法：强制杀死部分进程
- 进程回退法：让一个或多个进程回退到足以避免死锁的地步，回退时自愿释放资源而不是被剥夺



# 内存管理🔥

## 内存管理的概念

尽管计算机硬件技术飞速发展，内存容量也在不断增大，但是仍然不可能将所有的用户进程和系统需要的数据放入主存之中，因此操作系统必须对内存进行合理划分以及动态分配。

操作系统对内存进行划分以及动态分配，就是内存管理的概念。



## 内存管理的功能

### 程序装入与链接

创建程序首先要将程序和数据装入内存，将用户源程序变为可在内存中执行的程序。

通常要经过几个步骤：

1. 编译：编译程序将用户源代码编译成若干目标模块。

2. 链接：链接程序将编译后的目标模块与所需的库函数链接在一起，形成一个完整的装入模块。

   > 库函数：操作系统自带的 API，例如 fork() ，用来创建子进程。

   - 静态链接：程序运行就链接好了，之后不再拆开
   - 装入时动态链接：边装入内存边链接
   - 运行时动态链接✔️：程序执行到目标模块时才进行链接，便于修改和更新

3. 装入：由装入程序将装入模块装入内存运行。

   - 绝对装入：编译时就确定了程序在内存中的位置，仅适用于单道程序环境
   - 静态重定位装入：装入时一次性完成地址变换，同时必须分配程序要求的全部内存空间，否则无法装入。
   - 动态重定位装入✔️：地址变换推迟到程序运行时才进行，需要重定位寄存器的支持，可以将程序分配到不连续的存储区中，程序运行之前金装入部分代码就可以运行，在程序运行期间，动态地申请内存。



### 物理地址和逻辑地址

物理地址是指内存中物理单元的集合，是地址转换的最终地址，程序运行和访问数据，最终都要通过物理地址从主存中存取。

逻辑地址（虚拟地址）是程序产生的由段选择符和段内偏移地址组成的地址，逻辑地址的相对的。

编译后，每个目标模块都是从 0 号单元开始编址的，链接程序依次将各个模块的最终链接成一个从 0 号单元开始编址的程序，不同的程序可以有相同的逻辑地址，这些相同的逻辑地址最终会被映射到物理地址的不同位置。



### 内存保护

内存分配前，需要保护系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。

一般采用「重定位寄存器」和「界地址寄存器」实现

- 重定位寄存器（基址寄存器）：保存最小的物理地址值
- 界地址寄存器（限长寄存器）：保存最大的逻辑地址值

首先会将逻辑地址与界地址寄存器进行比较，如果没有发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。

<img src="http://store.secretcamp.cn/uPic/image-20210801234327094202108012343271627832607pqFZiQpqFZiQ.png" alt="image-20210801234327094" style="zoom:50%;" />



## 内存扩充

覆盖和交换都是用来扩充内存的方式。

### 覆盖

覆盖技术将用户空间分为一个固定区和若干个覆盖区，经常活跃的程序部分放在固定区常驻内存，其余部分按调用关系分段，即将要访问的段放在覆盖区，其他段放在外存之中。

- 优点：覆盖技术首次打破了必须将一个进程所有信息全部装入主存才能运行的限制

- 缺点：只有覆盖区中的段能被更新，固定区中的程序仍常驻主存，同时运行的代码量大于主存容量时仍不能运行，简单地说做的仍然不够好。

由于虚拟内存技术的应用，覆盖技术已经成为历史。



### 交换

交换的基本思想是：把处于等待状态的程序从内存移到外存，把内存空间腾出来，这一过程叫做 “换出” ；把准备好竞争 CPU 运行的程序从外存移到内存，这一过程叫做 “换入” 。

为了有效利用 CPU ，需要每个进程的执行时间都比交换时间长。交换通常在内存紧张时开始进行，在系统负荷降低时暂停。

交换技术主要在不同程序之间进行，而覆盖则是用于同一个程序中。

目前，交换技术仍然在现代操作系统中大量使用。





## 内存连续分配方式

### 单一连续分配

内存分为系统区和用户区，系统区仅供操作系统使用，在内存的低地址部分。这种分区方式无需内存保护，因为内存中永远只有一道程序

只能用于单用户、单任务的操作系统中，存储器利用率低，有内部碎片。



### 固定分区

固定分区的方式将用户内存空间划分为若干固定大小的区域，每个分区只装入一道作业。

并不是所有程序都能正好利用完分配的空间，所以固定分区的分配方式会产生 "内部碎片"

> 内部碎片：程序小于固定分区大小时，也占用一整个内存分区空间，这样造成了分区内部空间浪费。



### 动态分区

动态分区的方式不预先划分内存，而是在程序装入时，根据进程的大小动态地建立分区，使分区大小正好满足程序的需要。

随着系统的运行，程序不断换入与换出，内存中会产生很多无法被利用的空间碎片，无法建立分区，被称为 "外部碎片"

> 外部碎片：由于空间太小，导致无法分配给任何申请内存空间的新进程的内存空闲区域。

动态分区空间分配的几种算法：

- 首次适应算法
- 最佳适应算法
- 最坏适应算法
- 邻近适应算法



## 内存非连续分配方式

非连续分配管理方式根据分区的大小是否固定，分为 "分页存储管理方式" 和 "分段存储管理方式"

对于 "分页存储管理方式" ，又分为 "基本分页存储管理方式" 和 "请求分页存储管理方式"



### 基本分页存储管理方式💥

“分页” 是指将主存空间划分为大小相等且固定的 “块” 作为主存的基本单位。每个进程也以块为单位，在执行时会逐个申请内存中的块空间。

进程只可能在最后一个申请的块中产生内存碎片，因此，每个进程平均只生成半个块的内存碎片。



#### 页面和页面大小

进程中的块称为页（Page），内存中的块称为页框或页帧（Page Frame），外存中的块则直接称为块（Block），这三种描述是对应的。

进程在执行时需要为页申请页框，这就形成了页与页框的一一对应。

页的大小应是 2 的次方数，这样有利于内存分配。页大小应该适中，不宜过小或过大，如果过小，会导致进程的页面数较多，页表就会过长；如果过大，就会使内存碎片增多，降低内存的利用率。

在 Linux 操作系统中，块的大小为 4096bytes = 4 * 1024bytes = 4kb 



#### 虚拟地址结构

虚拟地址长度为 32 位，分为两个部分：

- 虚拟页号： 12 ~ 31 位，最多允许 $2^{20}$ 页
- 页内偏移量： 0 ~ 11 位，每页的大小为 4kb

```ruby
|--------------------------------------------------------------|
| 31            ...               12 | 11         ...        0 |
|------------------------------------|-------------------------|
|          虚拟页号　           　     |     页内偏移量　　　　　　　|
|------------------------------------|-------------------------|
```





#### 页表

将用户程序的程序逻辑地址转换成内存中的物理地址是通过页表（Page Table）实现的。

系统为每个进程建立一张页表，页表记录了逻辑地址和物理地址的关系，它记录页面在内存中对应的物理块号，页表存放在内存中。

页表由「页表项」组成，页表项的第一个部分是「页号」，第二个部分是「页框号」，即物理地址的块号。

进程的逻辑地址被分为若干页，每个页的编号就是「页号」，物理块号则对应了物理空间的地址。

<img src="http://store.secretcamp.cn/uPic/image-202108012354536802021080123545316278332934VWhyg4VWhyg.png" alt="image-20210801235453680" style="zoom:50%;" />



#### 地址变换机构

地址变换机构的作用是将「虚拟地址」转换为内存中的「物理地址」。

在系统中通常设置一个页表寄存器（PTR），存放页表在内存的起始位置 F 和页表长度 M ，每个进程都对应一个页表，进程未执行时，两者存放在 PCB 中，进程执行时，才将两者存入 PTR 之中。

<img src="http://store.secretcamp.cn/uPic/image-20210801235647609202108012356471627833407s2LlRDs2LlRD.png" alt="image-20210801235647609" style="zoom:50%;" />



地址变换步骤：

设页面大小为 L ，逻辑地址为 A ，物理地址为 E， 目标：A -> E

1. 首先计算进程中页面的页号P（P=A/L） 以及页内偏移量W（W=A%L）
2. 比较页号 P 与页表长度 M ，如果 P>M ，则产生越界中断，否则继续执行
3. 计算页号 P 对应的页表项地址 = 页表始地址 F + 页号 P * 页表项长度 ，根据该地址取出物理块号b
4. 物理地址 E = 物理块号 b * 页面大小L + 页内偏移量W

   

例子：

页面大小 L = 1kb
页号2中存储的物理块号 b = 8
求计算逻辑地址 A = 2500 的物理地址 E

1. 页号P = 2500/1K = 2，页内偏移量W = 2500%1K = 452
2. 页号P < 页表长度W 没问题
3. 已经知道对应的物理块号 b = 8 了
4. 物理地址 E = b * L + W = 8 * 1024 + 452 = 8644



#### 快表

根据地址变换机构可知，如果页表存放在内存中，那么存取一个数据或指令则至少要访问两次内存。第一次是访问页表获取物理地址，第二次是根据物理地址存取数据。

于是，在地址变换机构中增设一个高速缓冲存储器 — 快表 ，加速地址变换的过程。

一般快表的命中率高达 90% ，这要得益于局部性原理。

步骤：

1. 依然是计算页号和偏移量
2. 将页号送入快表，并与快表中所有页号进行比较
	- 如果找到页号，则说明要访问的页在快表中，直接取出该页对应的页框号（物理地址的块号）
	- 如果没找到，则需要访问主存中的页表，并将结果存入快表
3. 最后，如果快表满了，需要通过淘汰算法进行换出

![image-20210802000055232](http://store.secretcamp.cn/uPic/image-20210802000055232202108020000551627833655LfaSiALfaSiA.png)



#### 两级页表

二级页表，实际上就是构造一个页表的页表

以 32 位逻辑地址，页面大小为 4kb ，页表项大小为 4bit 为例，如果要实现对全部逻辑空间的映射，则每个进程需要 $2^{20}=1048576$​  个页表项，需要页表大小是 4mb ，这显然是不能接受的。

为了压缩页表，于是在页表之上再建立一层页表，用于存储页表的映射关系，这称为二级页表。

将虚拟地址的页号（12 ~ 31 位，共 20 位）分为两个 10 位，分别供一级页表和二级页表映射。将一级页表分为 1024 个页表项，每个页表项对应一个二级页表，每个二级表中包含 1024 个页表项。

 <img src="http://store.secretcamp.cn/uPic/image-20210507152324593202105071523241620372204OJKHTvOJKHTv.png" alt="image-20210507152324593" style="zoom:50%;" />



以一个逻辑地址为例，将逻辑地址转换为物理地址

```
 31 - 22      21 - 12       11 - 0
0000000000  0000000001  111111111111
```

1. 先根据 0000000000 查询一级页表中的内存块号，得到二级页表的起始地址
2. 再根据 0000000001 查询二级页表中的内存块号，得到物理块号 b

<img src="http://store.secretcamp.cn/uPic/image-20210507154025820202105071540261620373226LsAueFLsAueF.png" alt="image-20210507154025820" style="zoom:50%;" />



### 基本分段存储管理方式

#### 分段

段式管理方式按照用户讲程中的自然段划分逻辑空间。



#### 段表

每个进程都有一张逻辑空间与内存空间映射的段表，其中每个段表项对应进程的一段，段表项记录该段在内存中的始址和长度。



#### 地址变换机构





### 段页式管理方式

页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。将这两种存储管理方法结合起来，便形成了段页式存储管理方式



## 虚拟内存的概念💥

虚拟内存的提出是为了在物理上扩展内存相对有限的情况下，尝试从逻辑上扩展内存空间。



### 传统存储管理方式的特征

1. 一次性：作业必须一次性全部装入内存后，才能开始运行。
2. 驻留性：作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出。

这两个特点都会导致程序占用大量的内存空间，内存利用率低。



### 局部性原理

1. 时间局部性：序中的某条指令一执行，不久后该今可能再次执行。
2. 空间局部性：旦程序访问了某个存储单元，在不久后，其附近的存储单元也很可能被访问。



### 虚拟存储器

基于局部性原理，在程序装入时，将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序运行。

在程序运行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将暂时用不到的内容换出到外存上，从而腾出内存空间。

这样，操作空间似乎提供了一个比实际内存大得多的存储器，称为「虚拟存储器」，实际上这样的存储器并不存在。



### 虚拟内存技术的实现

虚拟内存允许将一个作业分多次调入内存，但如果采取连续分配方式，会使相当一部分内存处于暂时或永久的空闲状态，这会造成内存资源的严重浪费。因此，**虚拟内存的实现需要建立在离散分配内存管理方式的基础上。**

主要有以下三种方式：

- 请求分页存储管理
- 请求分段存储管理
- 请求段页式存储管理



## 请求分页管理方式💥

请求分页管理方式建立在基本分页管理方式之上，为了支持虚拟存储器的功能，增加了「请求调页」功能和「页面置换」功能。

在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存中时，再通过 “调页” 功能将其调入，同时还可通过 “置换” 功能将暂时不用的页面换出到外存上，以便腾出内存空间。

### 页表

请求分页管理方式的页表不同于基本分页的页表，也原页表的基础上新增了四个字段：

- 状态位 P：用于指示该页是否已调入内存，供程序访问时参考。

- 访问字段 A：用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问，供置换算法换出页面时参考。

- 修改位 M：标识该页在调入内存后是否被修改过。

- 外存地址：用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。

<img src="http://store.secretcamp.cn/uPic/image-20210802143436502VtjmRo1627886076738.png" alt="image-20210802143436502" style="zoom:50%;" />



### 缺页中断机构

每当要访问的页在内存中不存在时，便产生一个缺页中断，请求操作系统将缺的页调入内存。

此时应将缺页的进程阻塞，完成调页后再唤醒。若内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中的相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存）。



### 地址变换机构

请求分页的地址变换机构为了实现虚拟内存，在分页系统地址变换机构的基础上增加了某些功能而形成的。

![image-20210802150416935](http://store.secretcamp.cn/uPic/image-20210802150416935JIOm4Q1627887857196.png)



## 页面置换算法

### OPT

最佳置换算法（Optimal，OPT）选择的被淘汰页面是以后永不使用的页面，或是在最长时间内不再被访问的页面，以便保证获得最低的缺页率。然而，无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现，但可以用来评价其他算法。



### FIFO

先进先出页面置换算法（FIFO）优先淘汰最早进入内存的页面，即在内存中驻留时间最久的页面。该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。



### LRU

最近最久未使用置換算法（LRU）认为过去一段时间未访问过的页面，在将来也很有可能不被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。





## 页面分配策略

### 驻留集

对于请求分页管理方式，程序执行时酒精需要将多少页面读入内存，给一个进程分配多少物理页框，这被称为驻留集。

可变分配局部置换：为每个进程分配一定数量的物理块，当某个进程发生缺页时，只允许进程将页面置换出去，若进程频繁缺页，系统再为进程分配若干物理块，直到缺页率趋向于适当程度。



### 调入页面的时机

调页主要有两种策略：

1. 预调页策略：一次性调入与请求页相邻的若干页

   优点：根据局部性原理，这样调页方式更加高效

   缺点：依赖预测的准度，若调入的一批页面中大多数都未被访问，则又是低效的。

2. 请求调页策略：进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。

   优点：调入的页一定会被访问，且这种策略比较易于实现

   缺点：每次只调入一页，调入调出页面数多时会花费过多的 I/O 开销。



### 从何处调入页面

外存分为两个部分，用于存放文件的文件区和用于存放对换页面的对换区。

对换区通常采用连续分配方式，而文件区采用离散分配方式，因此对换区的磁盘 I/O 速度比文件区的更快。

- 系统有足够对换区空间：全部从对换区调入页面，提高调页速度
- 系统没有足够对换区空间：不会被修改的文件从文件区调入，由于这些文件不会被修改，所以换出时直接从内存中淘汰，不必换回磁盘。可能被修改的文件换出到对换区



## 抖动

在页面置换过程中，一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存，这种频繁的页面调度行为称为 “抖动”。若一个进程在换页上用的时间多于执行时间，则这个进程就在抖动。

频繁发生缺页抖动的主要原因是，某个进程频繁访问的页面数目高于可用的物理页帧数目。

虚拟内存技术可在内存中保留更多的进程以提高系统效率。在稳定状态，几乎主存的所有空间都被进程块占据，处理机和操作系统可以直接访问到尽可能多的进程。然而，如果管理不当，那么处理机的大部分时间都将用于交换块，即请求调入页面的操作，而不是执行进程的指令，因此会大大降低系统效率。



## 工作集

工作集是指在某段时间间隔内，进程要访问的页面集合。基于局部性原理，可以用最近访问过的页面来确定工作集。



## 地址翻译

进程在运行期间产生的内存地址都是虚拟地址，如果计算机没有引入虚拟内存这种存储器抽象技术的话，CPU 会把这些地址直接发送到内存地址总线上，然后访问和虚拟地址相同值的物理地址；如果使用虚拟内存技术的话，CPU 则是把这些虚拟地址通过地址总线送到内存管理单元（Memory Management Unit，MMU），MMU 将虚拟地址翻译成物理地址之后再通过内存总线去访问物理内存。

虚拟地址（比如 16 位地址 8196 = 0010 000000000100）分为两部分：

- 虚拟页号（Virtual Page Number，简称 VPN，这里是高 4 位部分）
- 偏移量（Virtual Page Offset，简称 VPO，这里是低 12 位部分）



# 文件管理🔥







# I/O管理🔥



